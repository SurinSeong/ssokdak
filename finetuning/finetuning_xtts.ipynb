{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232b96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c114617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 2) ë””ë°”ì´ìŠ¤ ì„¤ì •: CUDAê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU('cuda')ë¥¼, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ CPU('cpu')ë¥¼ ì‚¬ìš©\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using device: {device}\")  # ì„ íƒëœ ë””ë°”ì´ìŠ¤(ì˜ˆ: cuda ë˜ëŠ” cpu)ë¥¼ ì½˜ì†”ì— ì¶œë ¥í•˜ì—¬ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig\n",
    "from TTS.utils.manage import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e345bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.models.xtts import XttsAudioConfig\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class XttsAudioConfig(XttsAudioConfig):\n",
    "    dvae_sample_rate: int = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d053cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging parameters\n",
    "RUN_NAME = \"GPT_XTTS_v2.0_SSOKDAK_FT\"\n",
    "PROJECT_NAME = \"XTTS_trainer\"\n",
    "DASHBOARD_LOGGER = \"tensorboard\"\n",
    "LOGGER_URI = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa57be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/finetuning-output/run/training'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set here the path that the checkpoints will be saved. Default: ./run/training/\n",
    "output_path = \"C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/finetuning-output\"\n",
    "\n",
    "OUT_PATH = output_path + \"/run/training\"\n",
    "OUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "707c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "OPTIMIZER_WD_ONLY_ON_WEIGHTS = True  # for multi-gpu training please make it False\n",
    "START_WITH_EVAL = True  # if True it will star with evaluation\n",
    "BATCH_SIZE = 3  # set here the batch size\n",
    "GRAD_ACUMM_STEPS = 84  # set here the grad accumulation steps\n",
    "# Note: we recommend that BATCH_SIZE * GRAD_ACUMM_STEPS need to be at least 252 for more efficient training. You can increase/decrease BATCH_SIZE but then set GRAD_ACUMM_STEPS accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccddb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define here the dataset that you want to use for the fine-tuning on.\n",
    "config_dataset = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    dataset_name=\"korean-single-speaker-datasets\",\n",
    "    path=\"C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/korean-single-speaker-datasets\",\n",
    "    meta_file_train=\"C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/korean-single-speaker-datasets/metadata.txt\",\n",
    "    language=\"ko\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b4004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add here the configs of the datasets\n",
    "DATASETS_CONFIG_LIST = [config_dataset]\n",
    "\n",
    "# Define the path where XTTS v2.0.1 files will be downloaded\n",
    "CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"XTTS_v2.0_original_model_files/\")\n",
    "os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5750421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading DVAE files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.07k/1.07k [00:00<00:00, 2.01kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading XTTS v2.0 files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 211M/211M [01:21<00:00, 2.58MiB/s]\n",
      "361kiB [00:00, 617kiB/s]\n"
     ]
    }
   ],
   "source": [
    "# DVAE files\n",
    "DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
    "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
    "\n",
    "# Set the path to the downloaded files\n",
    "DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n",
    "MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n",
    "\n",
    "# download DVAE files if needed\n",
    "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
    "    print(\" > Downloading DVAE files!\")\n",
    "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n",
    "\n",
    "\n",
    "# Download XTTS v2.0 checkpoint if needed\n",
    "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
    "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
    "\n",
    "# XTTS transfer learning parameters: You we need to provide the paths of XTTS model checkpoint that you want to do the fine tuning.\n",
    "TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json file\n",
    "XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth file\n",
    "\n",
    "# download XTTS v2.0 files if needed\n",
    "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
    "    print(\" > Downloading XTTS v2.0 files!\")\n",
    "    ModelManager._download_model_files(\n",
    "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2dfc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Training sentences generations\n",
    "SPEAKER_REFERENCE = [\n",
    "    \"C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/korean-single-speaker-datasets/wavs/1_0000.wav\"  # speaker reference to be used in training test sentences\n",
    "]\n",
    "LANGUAGE = config_dataset.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e48c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # init args and config\n",
    "    model_args = GPTArgs(\n",
    "        max_conditioning_length=132300,  # 6 secs\n",
    "        min_conditioning_length=22050,  # 1 secs\n",
    "        debug_loading_failures=False,\n",
    "        max_wav_length=255995,  # ~11.6 seconds\n",
    "        max_text_length=200,\n",
    "        mel_norm_file=MEL_NORM_FILE,\n",
    "        dvae_checkpoint=DVAE_CHECKPOINT,\n",
    "        xtts_checkpoint=XTTS_CHECKPOINT,  # checkpoint path of the model that you want to fine-tune\n",
    "        tokenizer_file=TOKENIZER_FILE,\n",
    "        gpt_num_audio_tokens=1026,\n",
    "        gpt_start_audio_token=1024,\n",
    "        gpt_stop_audio_token=1025,\n",
    "        gpt_use_masking_gt_prompt_approach=True,\n",
    "        gpt_use_perceiver_resampler=True,\n",
    "    )\n",
    "    # define audio config\n",
    "    audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000)\n",
    "    # training parameters config\n",
    "    config = GPTTrainerConfig(\n",
    "        output_path=OUT_PATH,\n",
    "        model_args=model_args,\n",
    "        run_name=RUN_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        run_description=\"\"\"\n",
    "            GPT XTTS training\n",
    "            \"\"\",\n",
    "        dashboard_logger=DASHBOARD_LOGGER,\n",
    "        logger_uri=LOGGER_URI,\n",
    "        audio=audio_config,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        batch_group_size=48,\n",
    "        eval_batch_size=BATCH_SIZE,\n",
    "        num_loader_workers=8,\n",
    "        eval_split_max_size=256,\n",
    "        print_step=50,\n",
    "        plot_step=100,\n",
    "        log_model_step=1000,\n",
    "        save_step=10000,\n",
    "        save_n_checkpoints=1,\n",
    "        save_checkpoints=True,\n",
    "        # target_loss=\"loss\",\n",
    "        print_eval=False,\n",
    "        # Optimizer values like tortoise, pytorch implementation with modifications to not apply WD to non-weight parameters.\n",
    "        optimizer=\"AdamW\",\n",
    "        optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n",
    "        optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
    "        lr=5e-06,  # learning rate\n",
    "        lr_scheduler=\"StepLR\",\n",
    "        # it was adjusted accordly for the new step scheme\n",
    "        lr_scheduler_params={\"step_size\": 50, \"gamma\": 0.5, \"last_epoch\": -1},\n",
    "        test_sentences=[\n",
    "            {\n",
    "                \"text\": \"ë‚˜ì—ê²ŒëŠ” ê·¸ë“¤ë³´ë‹¤ ì´ ì ë“±ì¸ì´ ë” ë‚˜ì€ ì‚¬ëžŒì´ì•¼. ì ì–´ë„ ì ë“±ì¸ì€ ê·¸ë“¤ê³¼ëŠ” ë‹¬ë¦¬, ë‚¨ì„ ìœ„í•´ ì¼í•˜ê¸° ë•Œë¬¸ì´ì•¼. ë„ˆëŠ” ë‚˜ì—ê²Œ ì´ ì„¸ìƒì— ë‹¨ í•˜ë‚˜ë¿ì¸ ì¡´ìž¬ê°€ ë˜ëŠ” ê±°ê³ , ë‚˜ë„ ë„ˆì—ê²Œ ì„¸ìƒì— í•˜ë‚˜ë¿ì¸ ì¡´ìž¬ê°€ ë˜ëŠ” ê±°ì•¼.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ë„Œ ë„¤ê°€ ê¸¸ë“¤ì¸ ê²ƒì— ì˜ì›ížˆ ì±…ìž„ì´ ìžˆì–´. ëˆ„êµ°ê°€ì—ê²Œ ê¸¸ë“¤ì—¬ì§„ë‹¤ëŠ” ê²ƒì€ ëˆˆë¬¼ì„ í˜ë¦´ ì¼ì´ ìƒê¸´ë‹¤ëŠ” ëœ»ì¼ì§€ë„ ëª°ë¼. ë„¤ ìž¥ë¯¸ê½ƒì´ ì†Œì¤‘í•œ ì´ìœ ëŠ” ê·¸ ê½ƒì„ ìœ„í•´ ë„¤ê°€ ì• ì“´ ì‹œê°„ ë•Œë¬¸ì´ì•¼. ë‹¤ë¥¸ ì‚¬ëžŒì—ê²ŒëŠ” ì—´ì–´ì£¼ì§€ ì•ŠëŠ” ë¬¸ì„ ë‹¹ì‹ ì—ê²Œë§Œ ì—´ì–´ì£¼ëŠ” ì‚¬ëžŒì´ ìžˆë‹¤ë©´ ê·¸ ì‚¬ëžŒì€ ë‹¹ì‹ ì˜ ì§„ì •í•œ ì¹œêµ¬ì´ë‹¤.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì„¸ìƒì—ì„œ ê°€ìž¥ ì–´ë ¤ìš´ ì¼ì€ ì‚¬ëžŒì´ ì‚¬ëžŒì˜ ë§ˆìŒì„ ì–»ëŠ” ì¼ì´ì•¼. ë‚´ê°€ ì¢‹ì•„í•˜ëŠ” ì‚¬ëžŒì´ ë‚˜ë¥¼ ì¢‹ì•„í•´ ì£¼ëŠ” ê±´ ê¸°ì ì´ì•¼.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì§ˆë¬¸ì„ í•˜ì§€ ì•Šìœ¼ë©´ ì„¸ìƒ ì¼ì„ ì–´ë–»ê²Œ ì•Œê² ì–´ìš”?\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì„¸ìƒì—” ìž¬ë¯¸ìžˆëŠ” ì¼ì´ ì°¸ ë§Žì•„ìš”. ìš°ë¦¬ê°€ ëª¨ë“  ê±¸ ë‹¤ ì•ˆë‹¤ë©´ ì‚¬ëŠ” ìž¬ë¯¸ê°€ ë°˜ìœ¼ë¡œ ì¤„ì–´ë“¤ ê±°ì˜ˆìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ë˜ ë‹¤ë¥¸ ê±±ì •ê±°ë¦¬ë“¤ì´ ìƒê¸¸ ê±°ì˜ˆìš”. í•­ìƒ ê³¨ì¹˜ ì•„í”ˆ ì¼ë“¤ì€ ìƒˆë¡­ê²Œ ì¼ì–´ë‚˜ë‹ˆê¹Œìš”. í•œ ê°€ì§€ê°€ í•´ê²°ë˜ë©´ ë˜ ë‹¤ë¥¸ ë¬¸ì œê°€ ì´ì–´ì§€ì£ . ë‚˜ì´ë¥¼ ë¨¹ìœ¼ë‹ˆ ìƒê°í•  ê²ƒë„, ê²°ì •í•´ì•¼ í•  ì¼ë„ ë§Žì•„ì ¸ìš”. ë­ê°€ ì˜³ì€ì§€ ê³°ê³°ì´ ìƒê°í•˜ê³  ê²°ì •í•˜ëŠë¼ ëŠ˜ ë°”ë¹ ìš”. ì–´ë¥¸ì´ ëœë‹¤ëŠ” ê±´ ì‰¬ìš´ ì¼ì´ ì•„ë‹ˆì—ìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì´ ì„¸ìƒì—ì„œ ë¬´ì–¸ê°€ë¥¼ ì–»ê±°ë‚˜ ì´ë£¨ë ¤ë©´ ë°˜ë“œì‹œ ê·¸ë§Œí•œ ëŒ€ê°€ë¥¼ ì¹˜ëŸ¬ì•¼ í•œë‹¤. ì•¼ë§ì„ í’ˆëŠ” ê²ƒì€ ê°€ì¹˜ ìžˆëŠ” ì¼ì´ì§€ë§Œ í•©ë‹¹í•œ ë…¸ë ¥ê³¼ ì ˆì œì™€ ë¶ˆì•ˆê³¼ ì¢Œì ˆ ì—†ì´ ì–»ì–´ì§€ì§€ëŠ” ì•ŠëŠ” ë²•ì´ë‹¤.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì•¤ì€ ë°œ ì•žì— ë†’ì¸ ê¸¸ì´ ì•„ë¬´ë¦¬ ì¢ë”ë¼ë„ ê·¸ ê¸¸ì„ ë”°ë¼ ìž”ìž”í•œ í–‰ë³µì˜ ê½ƒì´ í”¼ì–´ë‚œë‹¤ëŠ” ê±¸ ì•Œê³  ìžˆì—ˆë‹¤. ì •ì§í•œ ì¼ê³¼ í›Œë¥­í•œ í¬ë¶€ì™€ ë§ˆìŒ ë§žëŠ” ì¹œêµ¬ê°€ ìžˆë‹¤ëŠ” ê¸°ì¨ì€ ì˜¨ì „ížˆ ì•¤ì˜ ê²ƒì´ì—ˆë‹¤.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì•„ë¬´ë¦¬ í™©ëŸ‰í•˜ê³  ë”°ë¶„í•´ë„ ë‹¤ë¥¸ ì•„ë¦„ë‹¤ìš´ ê³³ë³´ë‹¤ ê³ í–¥ì—ì„œ ì‚´ê³  ì‹¶ì–´ í•˜ëŠ” ê²Œ ì‚¬ëžŒì´ì—ìš”. ì„¸ìƒì— ì§‘ë³´ë‹¤ ì¢‹ì€ ê³³ì€ ì—†ê±°ë“ ìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ë°”ë³´ë“¤ì€ ì‹¬ìž¥ì´ ìžˆì–´ë„ ê·¸ê±¸ë¡œ ë¬´ì—‡ì„ í•´ì•¼ í•˜ëŠ”ì§€ ëª°ë¼ìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì‚´ì•„ ìžˆëŠ” ì¡´ìž¬ë¼ë©´ ëˆ„êµ¬ë‚˜ ìœ„í—˜ ì•žì—ì„œ ë‘ë ¤ì›€ì„ ëŠê»´. ì§„ì •í•œ ìš©ê¸°ëž€ ë‘ë ¤ì›€ì—ë„ ë¶ˆêµ¬í•˜ê³  ìœ„í—˜ì— ë§žì„œëŠ” ê²ƒì¸ë°, ë„ˆëŠ” ì´ë¯¸ ê·¸ëŸ° ìš©ê¸°ë¥¼ ì¶©ë¶„ížˆ ê°–ê³  ìžˆì–´.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ë„ˆëŠ” ìž‘ê°€ê°€ ë˜ì§€ ì•Šì•„ë„, ë°°ìš°ê°€ ë˜ì§€ ì•Šì•„ë„, ê·¸ì € ë„ˆì´ê¸°ì— ì‚¬ëž‘ìŠ¤ëŸ½ê³  ì™„ì „í•œ ì¡´ìž¬ëž€ë‹¤. ë‹¤ë¥¸ ë¬´ì—‡ì´ ë˜ë ¤ê³  ì• ì“°ì§€ ì•Šì•„ë„ ì¢‹ì•„. ë„ˆëŠ” ê·¸ì € ë„ˆ, ë„ˆë‹¤ìš´ ë„ˆì´ê¸°ë§Œ í•˜ë©´ ëœë‹¨ë‹¤.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì†Œì„¤ì„ ì“°ë©° ì‚¬ëŠ” ì‚¶ë³´ë‹¤ ì†Œì„¤ì²˜ëŸ¼ ì‚´ì•„ê°€ëŠ” ì‚¶ì´ í›¨ì”¬ ë” ìž¬ë¯¸ìžˆì„ ê±°ì˜ˆìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì €ëŠ” ë§¤ ìˆœê°„ ì œê°€ í–‰ë³µí•˜ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì˜¨ì „ížˆ ëŠê»´ìš”. ì•„ë¬´ë¦¬ ì†ìƒí•œ ì¼ì´ ìƒê²¨ë„ ê·¸ ì‚¬ì‹¤ì„ ìžŠì§€ ì•Šì„ ê±°ì˜ˆìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì €ëŠ” ì¸ê°„ì—ê²Œ ê°€ìž¥ í•„ìš”í•œ ìžì§ˆì€ ìƒìƒë ¥ì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤. ìƒìƒë ¥ì´ ìžˆì–´ì•¼ íƒ€ì¸ì„ ì´í•´í•  ìˆ˜ ìžˆê³ , ê·¸ëž˜ì•¼ ì¹œì ˆí•  ìˆ˜ë„, ë‚¨ì„ ì´í•´í•  ìˆ˜ë„, ë˜ ë™ì •í•  ìˆ˜ë„ ìžˆìœ¼ë‹ˆê¹Œìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ìžì‹ ì—ê²Œ ì°¾ì•„ì˜¤ëŠ” ê¸°íšŒë¥¼ ë¶™ìž¡ì„ ì˜ì§€ë§Œ ìžˆë‹¤ë©´ ì„¸ìƒì€ í–‰ë³µìœ¼ë¡œ ê°€ë“ ì°¨ ìžˆê³ , ê°€ë³¼ ê³³ë„ ë§Žì•„ìš”. ë¹„ë²•ì€ ë°”ë¡œ ìœ ì—°í•œ ë§ˆìŒì´ì—ìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ì •ë§ ì†Œì¤‘í•œ ê²ƒì€ ì»¤ë‹¤ëž€ ê¸°ì¨ì´ ì•„ë‹ˆì—ìš”. ì‚¬ì†Œí•œ ê³³ì—ì„œ ì–»ëŠ” ê¸°ì¨ì´ ë” ì¤‘ìš”í•´ìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"í° ì‹œë ¨ì´ ë‹¥ì³¤ì„ ë•Œë§Œ ì¸ê²©ì´ í•„ìš”í•œ ê²Œ ì•„ë‹ˆì—ìš”. ìœ„ê¸°ì— ëŒ€ì²˜í•˜ê±°ë‚˜, ì¹˜ëª…ì ì¸ ë¹„ê·¹ì— ë§žì„œëŠ” ê±´ ëˆ„êµ¬ë‚˜ í•  ìˆ˜ ìžˆì§€ë§Œ, ê·¸ë‚ ê·¸ë‚ ì˜ ì‚¬ì†Œí•œ ë¶ˆìš´ë“¤ì„ ì›ƒìŒìœ¼ë¡œ ë„˜ê¸°ëŠ” ì¼ì€ 'ì •ì‹ ë ¥'ì´ ì—†ë‹¤ë©´ ë¶ˆê°€ëŠ¥í•œ ì¼ì´ì—ìš”. ì œê°€ í‚¤ì›Œë‚˜ê°€ì•¼ í•  ê²Œ ë°”ë¡œ ì´ëŸ° ì¢…ë¥˜ì˜ ì¸ê²©ì´ì—ìš”.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ëˆˆì´ ë³´ì´ì§€ ì•Šìœ¼ë©´ ëˆˆì´ ë³´ì´ëŠ” ì½”ë¼ë¦¬ì™€ ì‚´ì„ ë§žëŒ€ê³  ê±¸ìœ¼ë©´ ë˜ê³ , ë‹¤ë¦¬ê°€ ë¶ˆíŽ¸í•˜ë©´ ë‹¤ë¦¬ê°€ íŠ¼íŠ¼í•œ ì½”ë¼ë¦¬ì—ê²Œ ê¸°ëŒ€ì„œ ê±¸ìœ¼ë©´ ë¼. ê°™ì´ ìžˆìœ¼ë©´ ê·¸ëŸ° ê±´ í° ë¬¸ì œê°€ ì•„ë‹ˆì•¼.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"ëˆ„êµ¬ë“  ë„ˆë¥¼ ì¢‹ì•„í•˜ê²Œ ë˜ë©´, ë„¤ê°€ ëˆ„êµ¬ì¸ì§€ ì•Œì•„ë³¼ ìˆ˜ ìžˆì–´. ì•„ë§ˆ ì²˜ìŒì—ëŠ” í˜¸ê¸°ì‹¬ìœ¼ë¡œ ë„ˆë¥¼ ê´€ì°°í•˜ê² ì§€. í•˜ì§€ë§Œ ì  ë„ˆë¥¼ ì¢‹ì•„í•˜ê²Œ ë˜ì–´ì„œ ë„ˆë¥¼ ëˆˆì—¬ê²¨ë³´ê²Œ ë˜ê³ , ë„¤ê°€ ê°€ê¹Œì´ ìžˆì„ ë•ŒëŠ” ì–´ë–¤ ëƒ„ìƒˆê°€ ë‚˜ëŠ”ì§€ ì•Œê²Œ ë  ê±°ê³ , ë„¤ê°€ ê±¸ì„ ë•ŒëŠ” ì–´ë–¤ ì†Œë¦¬ê°€ ë‚˜ëŠ”ì§€ì—ë„ ê·€ ê¸°ìš¸ì´ê²Œ ë  ê±°ì•¼. ê·¸ê²Œ ë°”ë¡œ ë„ˆì•¼.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # init the model from config\n",
    "    model = GPTTrainer.init_from_config(config)\n",
    "\n",
    "    # load training samples\n",
    "    train_samples, eval_samples = load_tts_samples(\n",
    "        DATASETS_CONFIG_LIST,\n",
    "        eval_split=True,\n",
    "        eval_split_max_size=config.eval_split_max_size,\n",
    "        eval_split_size=config.eval_split_size,\n",
    "    )\n",
    "\n",
    "    # init the trainer and ðŸš€\n",
    "    trainer = Trainer(\n",
    "        TrainerArgs(\n",
    "            restore_path=None,  # xtts checkpoint is restored via xtts_checkpoint key so no need of restore it using Trainer restore_path parameter\n",
    "            skip_train_epoch=False,\n",
    "            start_with_eval=START_WITH_EVAL,\n",
    "            grad_accum_steps=GRAD_ACUMM_STEPS,\n",
    "        ),\n",
    "        config,\n",
    "        output_path=OUT_PATH,\n",
    "        model=model,\n",
    "        train_samples=train_samples,\n",
    "        eval_samples=eval_samples,\n",
    "    )\n",
    "    trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bf371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 22\n",
      " | > Num. of Torch Threads: 1\n",
      " | > Torch seed: 1\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=C:\\Users\\SSAFY\\Desktop\\git-repos\\ssokdak\\tts-coqui\\finetuning-output\\run\\training\\GPT_XTTS_v2.0_SSOKDAK_FT-August-04-2025_02+32AM-d4b58e3\n",
      "\n",
      " > Model has 518442047 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
      " --> C:\\Users\\SSAFY\\Desktop\\git-repos\\ssokdak\\tts-coqui\\finetuning-output\\run\\training\\GPT_XTTS_v2.0_SSOKDAK_FT-August-04-2025_02+32AM-d4b58e3\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.024030713807968868 \u001b[0m(+0.0)\n",
      "     | > avg_loss_text_ce: 0.02705517690628767 \u001b[0m(+0.0)\n",
      "     | > avg_loss_mel_ce: 3.8821001790818714 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 3.9091553688049316 \u001b[0m(+0.0)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/1000\u001b[0m\n",
      " --> C:\\Users\\SSAFY\\Desktop\\git-repos\\ssokdak\\tts-coqui\\finetuning-output\\run\\training\\GPT_XTTS_v2.0_SSOKDAK_FT-August-04-2025_02+32AM-d4b58e3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-08-04 02:34:57) \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tts)",
   "language": "python",
   "name": "tts"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
