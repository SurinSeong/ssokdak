{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "232b96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c114617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 2) 디바이스 설정: CUDA가 사용 가능하면 GPU('cuda')를, 그렇지 않으면 CPU('cpu')를 사용\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(f\"Using device: {device}\")  # 선택된 디바이스(예: cuda 또는 cpu)를 콘솔에 출력하여 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.layers.xtts.trainer.gpt_trainer import GPTArgs, GPTTrainer, GPTTrainerConfig\n",
    "from TTS.utils.manage import ModelManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e345bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.models.xtts import XttsAudioConfig\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class XttsAudioConfig(XttsAudioConfig):\n",
    "    dvae_sample_rate: int = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d053cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging parameters\n",
    "RUN_NAME = \"GPT_XTTS_v2.0_SSOKDAK_FT\"\n",
    "PROJECT_NAME = \"XTTS_trainer\"\n",
    "DASHBOARD_LOGGER = \"tensorboard\"\n",
    "LOGGER_URI = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa57be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/finetuning-output/run/training'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set here the path that the checkpoints will be saved. Default: ./run/training/\n",
    "output_path = \"C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/finetuning-output\"\n",
    "\n",
    "OUT_PATH = output_path + \"/run/training\"\n",
    "OUT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "707c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "OPTIMIZER_WD_ONLY_ON_WEIGHTS = True  # for multi-gpu training please make it False\n",
    "START_WITH_EVAL = True  # if True it will star with evaluation\n",
    "BATCH_SIZE = 3  # set here the batch size\n",
    "GRAD_ACUMM_STEPS = 84  # set here the grad accumulation steps\n",
    "# Note: we recommend that BATCH_SIZE * GRAD_ACUMM_STEPS need to be at least 252 for more efficient training. You can increase/decrease BATCH_SIZE but then set GRAD_ACUMM_STEPS accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccddb069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define here the dataset that you want to use for the fine-tuning on.\n",
    "config_dataset = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\",\n",
    "    dataset_name=\"korean-single-speaker-datasets\",\n",
    "    path=\"C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/korean-single-speaker-datasets\",\n",
    "    meta_file_train=\"C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/korean-single-speaker-datasets/metadata.txt\",\n",
    "    language=\"ko\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b4004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add here the configs of the datasets\n",
    "DATASETS_CONFIG_LIST = [config_dataset]\n",
    "\n",
    "# Define the path where XTTS v2.0.1 files will be downloaded\n",
    "CHECKPOINTS_OUT_PATH = os.path.join(OUT_PATH, \"XTTS_v2.0_original_model_files/\")\n",
    "os.makedirs(CHECKPOINTS_OUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5750421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading DVAE files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.07k/1.07k [00:00<00:00, 2.01kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Downloading XTTS v2.0 files!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211M/211M [01:21<00:00, 2.58MiB/s]\n",
      "361kiB [00:00, 617kiB/s]\n"
     ]
    }
   ],
   "source": [
    "# DVAE files\n",
    "DVAE_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/dvae.pth\"\n",
    "MEL_NORM_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/mel_stats.pth\"\n",
    "\n",
    "# Set the path to the downloaded files\n",
    "DVAE_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(DVAE_CHECKPOINT_LINK))\n",
    "MEL_NORM_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(MEL_NORM_LINK))\n",
    "\n",
    "# download DVAE files if needed\n",
    "if not os.path.isfile(DVAE_CHECKPOINT) or not os.path.isfile(MEL_NORM_FILE):\n",
    "    print(\" > Downloading DVAE files!\")\n",
    "    ModelManager._download_model_files([MEL_NORM_LINK, DVAE_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True)\n",
    "\n",
    "\n",
    "# Download XTTS v2.0 checkpoint if needed\n",
    "TOKENIZER_FILE_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/vocab.json\"\n",
    "XTTS_CHECKPOINT_LINK = \"https://coqui.gateway.scarf.sh/hf-coqui/XTTS-v2/main/model.pth\"\n",
    "\n",
    "# XTTS transfer learning parameters: You we need to provide the paths of XTTS model checkpoint that you want to do the fine tuning.\n",
    "TOKENIZER_FILE = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(TOKENIZER_FILE_LINK))  # vocab.json file\n",
    "XTTS_CHECKPOINT = os.path.join(CHECKPOINTS_OUT_PATH, os.path.basename(XTTS_CHECKPOINT_LINK))  # model.pth file\n",
    "\n",
    "# download XTTS v2.0 files if needed\n",
    "if not os.path.isfile(TOKENIZER_FILE) or not os.path.isfile(XTTS_CHECKPOINT):\n",
    "    print(\" > Downloading XTTS v2.0 files!\")\n",
    "    ModelManager._download_model_files(\n",
    "        [TOKENIZER_FILE_LINK, XTTS_CHECKPOINT_LINK], CHECKPOINTS_OUT_PATH, progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2dfc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Training sentences generations\n",
    "SPEAKER_REFERENCE = [\n",
    "    \"C:/Users/SSAFY/Desktop/git-repos/ssokdak/tts-coqui/korean-single-speaker-datasets/wavs/1_0000.wav\"  # speaker reference to be used in training test sentences\n",
    "]\n",
    "LANGUAGE = config_dataset.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e48c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # init args and config\n",
    "    model_args = GPTArgs(\n",
    "        max_conditioning_length=132300,  # 6 secs\n",
    "        min_conditioning_length=22050,  # 1 secs\n",
    "        debug_loading_failures=False,\n",
    "        max_wav_length=255995,  # ~11.6 seconds\n",
    "        max_text_length=200,\n",
    "        mel_norm_file=MEL_NORM_FILE,\n",
    "        dvae_checkpoint=DVAE_CHECKPOINT,\n",
    "        xtts_checkpoint=XTTS_CHECKPOINT,  # checkpoint path of the model that you want to fine-tune\n",
    "        tokenizer_file=TOKENIZER_FILE,\n",
    "        gpt_num_audio_tokens=1026,\n",
    "        gpt_start_audio_token=1024,\n",
    "        gpt_stop_audio_token=1025,\n",
    "        gpt_use_masking_gt_prompt_approach=True,\n",
    "        gpt_use_perceiver_resampler=True,\n",
    "    )\n",
    "    # define audio config\n",
    "    audio_config = XttsAudioConfig(sample_rate=22050, dvae_sample_rate=22050, output_sample_rate=24000)\n",
    "    # training parameters config\n",
    "    config = GPTTrainerConfig(\n",
    "        output_path=OUT_PATH,\n",
    "        model_args=model_args,\n",
    "        run_name=RUN_NAME,\n",
    "        project_name=PROJECT_NAME,\n",
    "        run_description=\"\"\"\n",
    "            GPT XTTS training\n",
    "            \"\"\",\n",
    "        dashboard_logger=DASHBOARD_LOGGER,\n",
    "        logger_uri=LOGGER_URI,\n",
    "        audio=audio_config,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        batch_group_size=48,\n",
    "        eval_batch_size=BATCH_SIZE,\n",
    "        num_loader_workers=8,\n",
    "        eval_split_max_size=256,\n",
    "        print_step=50,\n",
    "        plot_step=100,\n",
    "        log_model_step=1000,\n",
    "        save_step=10000,\n",
    "        save_n_checkpoints=1,\n",
    "        save_checkpoints=True,\n",
    "        # target_loss=\"loss\",\n",
    "        print_eval=False,\n",
    "        # Optimizer values like tortoise, pytorch implementation with modifications to not apply WD to non-weight parameters.\n",
    "        optimizer=\"AdamW\",\n",
    "        optimizer_wd_only_on_weights=OPTIMIZER_WD_ONLY_ON_WEIGHTS,\n",
    "        optimizer_params={\"betas\": [0.9, 0.96], \"eps\": 1e-8, \"weight_decay\": 1e-2},\n",
    "        lr=5e-06,  # learning rate\n",
    "        lr_scheduler=\"StepLR\",\n",
    "        # it was adjusted accordly for the new step scheme\n",
    "        lr_scheduler_params={\"step_size\": 50, \"gamma\": 0.5, \"last_epoch\": -1},\n",
    "        test_sentences=[\n",
    "            {\n",
    "                \"text\": \"나에게는 그들보다 이 점등인이 더 나은 사람이야. 적어도 점등인은 그들과는 달리, 남을 위해 일하기 때문이야. 너는 나에게 이 세상에 단 하나뿐인 존재가 되는 거고, 나도 너에게 세상에 하나뿐인 존재가 되는 거야.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"넌 네가 길들인 것에 영원히 책임이 있어. 누군가에게 길들여진다는 것은 눈물을 흘릴 일이 생긴다는 뜻일지도 몰라. 네 장미꽃이 소중한 이유는 그 꽃을 위해 네가 애쓴 시간 때문이야. 다른 사람에게는 열어주지 않는 문을 당신에게만 열어주는 사람이 있다면 그 사람은 당신의 진정한 친구이다.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"세상에서 가장 어려운 일은 사람이 사람의 마음을 얻는 일이야. 내가 좋아하는 사람이 나를 좋아해 주는 건 기적이야.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"질문을 하지 않으면 세상 일을 어떻게 알겠어요?\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"세상엔 재미있는 일이 참 많아요. 우리가 모든 걸 다 안다면 사는 재미가 반으로 줄어들 거예요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"또 다른 걱정거리들이 생길 거예요. 항상 골치 아픈 일들은 새롭게 일어나니까요. 한 가지가 해결되면 또 다른 문제가 이어지죠. 나이를 먹으니 생각할 것도, 결정해야 할 일도 많아져요. 뭐가 옳은지 곰곰이 생각하고 결정하느라 늘 바빠요. 어른이 된다는 건 쉬운 일이 아니에요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"이 세상에서 무언가를 얻거나 이루려면 반드시 그만한 대가를 치러야 한다. 야망을 품는 것은 가치 있는 일이지만 합당한 노력과 절제와 불안과 좌절 없이 얻어지지는 않는 법이다.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"앤은 발 앞에 높인 길이 아무리 좁더라도 그 길을 따라 잔잔한 행복의 꽃이 피어난다는 걸 알고 있었다. 정직한 일과 훌륭한 포부와 마음 맞는 친구가 있다는 기쁨은 온전히 앤의 것이었다.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"아무리 황량하고 따분해도 다른 아름다운 곳보다 고향에서 살고 싶어 하는 게 사람이에요. 세상에 집보다 좋은 곳은 없거든요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"바보들은 심장이 있어도 그걸로 무엇을 해야 하는지 몰라요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"살아 있는 존재라면 누구나 위험 앞에서 두려움을 느껴. 진정한 용기란 두려움에도 불구하고 위험에 맞서는 것인데, 너는 이미 그런 용기를 충분히 갖고 있어.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"너는 작가가 되지 않아도, 배우가 되지 않아도, 그저 너이기에 사랑스럽고 완전한 존재란다. 다른 무엇이 되려고 애쓰지 않아도 좋아. 너는 그저 너, 너다운 너이기만 하면 된단다.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"소설을 쓰며 사는 삶보다 소설처럼 살아가는 삶이 훨씬 더 재미있을 거예요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"저는 매 순간 제가 행복하다는 사실을 온전히 느껴요. 아무리 속상한 일이 생겨도 그 사실을 잊지 않을 거예요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"저는 인간에게 가장 필요한 자질은 상상력이라고 생각합니다. 상상력이 있어야 타인을 이해할 수 있고, 그래야 친절할 수도, 남을 이해할 수도, 또 동정할 수도 있으니까요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"자신에게 찾아오는 기회를 붙잡을 의지만 있다면 세상은 행복으로 가득 차 있고, 가볼 곳도 많아요. 비법은 바로 유연한 마음이에요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"정말 소중한 것은 커다란 기쁨이 아니에요. 사소한 곳에서 얻는 기쁨이 더 중요해요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"큰 시련이 닥쳤을 때만 인격이 필요한 게 아니에요. 위기에 대처하거나, 치명적인 비극에 맞서는 건 누구나 할 수 있지만, 그날그날의 사소한 불운들을 웃음으로 넘기는 일은 '정신력'이 없다면 불가능한 일이에요. 제가 키워나가야 할 게 바로 이런 종류의 인격이에요.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"눈이 보이지 않으면 눈이 보이는 코끼리와 살을 맞대고 걸으면 되고, 다리가 불편하면 다리가 튼튼한 코끼리에게 기대서 걸으면 돼. 같이 있으면 그런 건 큰 문제가 아니야.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"누구든 너를 좋아하게 되면, 네가 누구인지 알아볼 수 있어. 아마 처음에는 호기심으로 너를 관찰하겠지. 하지만 점 너를 좋아하게 되어서 너를 눈여겨보게 되고, 네가 가까이 있을 때는 어떤 냄새가 나는지 알게 될 거고, 네가 걸을 때는 어떤 소리가 나는지에도 귀 기울이게 될 거야. 그게 바로 너야.\",\n",
    "                \"speaker_wav\": SPEAKER_REFERENCE,\n",
    "                \"language\": LANGUAGE,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # init the model from config\n",
    "    model = GPTTrainer.init_from_config(config)\n",
    "\n",
    "    # load training samples\n",
    "    train_samples, eval_samples = load_tts_samples(\n",
    "        DATASETS_CONFIG_LIST,\n",
    "        eval_split=True,\n",
    "        eval_split_max_size=config.eval_split_max_size,\n",
    "        eval_split_size=config.eval_split_size,\n",
    "    )\n",
    "\n",
    "    # init the trainer and 🚀\n",
    "    trainer = Trainer(\n",
    "        TrainerArgs(\n",
    "            restore_path=None,  # xtts checkpoint is restored via xtts_checkpoint key so no need of restore it using Trainer restore_path parameter\n",
    "            skip_train_epoch=False,\n",
    "            start_with_eval=START_WITH_EVAL,\n",
    "            grad_accum_steps=GRAD_ACUMM_STEPS,\n",
    "        ),\n",
    "        config,\n",
    "        output_path=OUT_PATH,\n",
    "        model=model,\n",
    "        train_samples=train_samples,\n",
    "        eval_samples=eval_samples,\n",
    "    )\n",
    "    trainer.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bf371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 22\n",
      " | > Num. of Torch Threads: 1\n",
      " | > Torch seed: 1\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=C:\\Users\\SSAFY\\Desktop\\git-repos\\ssokdak\\tts-coqui\\finetuning-output\\run\\training\\GPT_XTTS_v2.0_SSOKDAK_FT-August-04-2025_02+32AM-d4b58e3\n",
      "\n",
      " > Model has 518442047 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
      " --> C:\\Users\\SSAFY\\Desktop\\git-repos\\ssokdak\\tts-coqui\\finetuning-output\\run\\training\\GPT_XTTS_v2.0_SSOKDAK_FT-August-04-2025_02+32AM-d4b58e3\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "The text length exceeds the character limit of 95 for language 'ko', this might cause truncated audio.\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.024030713807968868 \u001b[0m(+0.0)\n",
      "     | > avg_loss_text_ce: 0.02705517690628767 \u001b[0m(+0.0)\n",
      "     | > avg_loss_mel_ce: 3.8821001790818714 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 3.9091553688049316 \u001b[0m(+0.0)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/1000\u001b[0m\n",
      " --> C:\\Users\\SSAFY\\Desktop\\git-repos\\ssokdak\\tts-coqui\\finetuning-output\\run\\training\\GPT_XTTS_v2.0_SSOKDAK_FT-August-04-2025_02+32AM-d4b58e3\n",
      "\n",
      "\u001b[1m > TRAINING (2025-08-04 02:34:57) \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tts)",
   "language": "python",
   "name": "tts"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
