{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1238ac43-132d-4c3e-9a8c-3e01dec79d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c029fa1-c99f-47de-b8cf-8ebb23ac3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boson_multimodal.serve.serve_engine import HiggsAudioServeEngine, HiggsAudioResponse\n",
    "from boson_multimodal.data_types import ChatMLSample, Message, AudioContent\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import time\n",
    "import click\n",
    "\n",
    "MODEL_PATH = \"bosonai/higgs-audio-v2-generation-3B-base\"\n",
    "AUDIO_TOKENIZER_PATH = \"bosonai/higgs-audio-v2-tokenizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e1eaf5-9415-4cd7-8b84-b56ac4474951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 프롬프트\n",
    "\n",
    "system_prompt = (\n",
    "    \"Generate audio following instruction.\\n\\n<|scene_desc_start|>\\nAudio is recorded from a quiet room.\\n<|scene_desc_end|>\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    Message(\n",
    "        role=\"system\",\n",
    "        content=system_prompt,\n",
    "    ),\n",
    "    Message(\n",
    "        role=\"user\",\n",
    "        content=\"안녕 내 이름은 쏙닥이야. 만나서 반가워. 앞으로 잘 지내자.\",\n",
    "    ),\n",
    "]\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b3706a-f15d-4e78-8d50-27aa65e83814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아이 목소리를 내보라고 해보기\n",
    "system_prompt = (\n",
    "    \"Generate audio following instruction.\\n\\n<|scene_desc_start|>\\nAudio is recorded from a quiet room.\\n<|scene_desc_end|>\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    Message(\n",
    "        role=\"system\",\n",
    "        content=system_prompt,\n",
    "    ),\n",
    "    Message(\n",
    "        role=\"user\",\n",
    "        content=\"안녕! 내 이름은 쏙닥이야. 만나서 반가워. 앞으로 잘 지내자.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dca7b104-b86b-4f73-9390-06d09abe3130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcabb39b-041b-4fef-9ea5-de266a6b95e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  4.26it/s]\n",
      "\u001b[32m2025-07-29 14:14:43.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mboson_multimodal.serve.serve_engine\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m212\u001b[0m - \u001b[1mLoaded model from bosonai/higgs-audio-v2-generation-3B-base, dtype: torch.bfloat16\u001b[0m\n",
      "\u001b[32m2025-07-29 14:14:43.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mboson_multimodal.serve.serve_engine\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m216\u001b[0m - \u001b[1mLoading tokenizer from bosonai/higgs-audio-v2-generation-3B-base\u001b[0m\n",
      "\u001b[32m2025-07-29 14:14:43.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mboson_multimodal.serve.serve_engine\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1mInitializing Higgs Audio Tokenizer\u001b[0m\n",
      "Fetching 6 files: 100%|██████████| 6/6 [00:00<00:00, 59353.36it/s]\n",
      "\u001b[32m2025-07-29 14:14:46.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mboson_multimodal.serve.serve_engine\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m274\u001b[0m - \u001b[1mCapturing CUDA graphs for each KV cache length\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "serve_engine = HiggsAudioServeEngine(MODEL_PATH, AUDIO_TOKENIZER_PATH, device=device)\n",
    "\n",
    "output: HiggsAudioResponse = serve_engine.generate(\n",
    "    chat_ml_sample=ChatMLSample(messages=messages),\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.3,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    stop_strings=[\"<|end_of_text|>\", \"<|eot_id|>\"],\n",
    ")\n",
    "torchaudio.save(f\"output.wav\", torch.from_numpy(output.audio)[None, :], output.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1796b-e263-45c2-8514-9602b9a7729e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tts)",
   "language": "python",
   "name": "tts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
