# 쏙닥

> 아이의 속마음을 쏙 알아듣고, 속닥속닥 비밀 얘기를 나누는 인형 친구

## 1. 💡 서비스 소개

**쏙닥**은 아이가 애착 인형과 자연스럽게 대화할 수 있도록 돕는 AI 음성 서비스입니다.

아이의 음성을 텍스트로 변환하고, 그 내용을 분석하여 아이의 감정을 파악하고 보호자에게 리포트를 제공합니다.

쏙닥은 단순한 장난감이 아닌, 아이의 감정을 이해하고 부모와 연결해주는 **정서 교감형 대화 도우미**입니다.

---

## 2. 🎯 주요 기능

### 🔊 대화 기능 (On-device 기반)

- 웨이크워드(시동어) 인식으로 대화 시작 (예: “쏙닥아”)
- 시동어 → 대화 → 종료의 흐름 제어
- 웨이크워드 커스터마이징 가능
- 대화 내용은 STT로 변환되어 서버로 전송 및 분석
- TTS를 통한 맞춤 목소리 제공

### 🧠 감정 분석 및 AI 리포트

- 대화 내용을 기반으로 감정 분석
- 이상 징후가 감지된 경우 부모 대시보드에 알림
- ‘AI 리포트’로 감정 변화 추이 제공
- 이상 키워드, 반복적 표현 등을 근거로 분석 결과 제공

### 👪 아이별 맞춤 대응

- 부모가 아이 정보를 입력 (이름, 나이, 성별, 건강상태, 관심사 등)
- 다자녀 관리 가능 (기기 및 리포트 분리)
- 개별 설정 기반 음성 모델 및 대화 시나리오 제공

### 📱 보호자 웹 대시보드

- 일일 리포트 및 감정 변화 시각화
- 위험 키워드 관리
- 기기 상태 모니터링 (연결 상태 등)
- 자녀 정보 관리

### 🔧 기기 관리

- 시리얼 넘버 기반 기기 등록
- 음성 모델 선택 및 미리 듣기 기능
- 전력 부족/기기 이상 발생 시 알림
- 다수 디바이스 분리 관리

### 📍 기타 기능

- 녹음 파일 저장 기한 설정

---

## 3. 📲 사용자 유형

### 👨‍👩‍👧 보호자 (웹 서비스)

- 비로그인 시: 서비스 소개
- 로그인 후: 자녀 등록, 대시보드 확인, 기기 설정 등

### 🧒 아이 (기기 사용)

- 애착 인형과 자연스럽게 대화
- 거부감 없도록 친근한 음성 사용
- 감정 표현 및 비언어적 소통 가능

### 🧸 인형 디바이스

- 음성 수신 및 STT 기능
- 대화 유도, 질문, 반응 등 기본 시나리오 수행
- 목소리 커스터마이징 (친숙한 음색 제공)
- GPS, 충전 기능 포함

---

## 4. ⚠️ 윤리 및 보안 고려사항

- 부모의 커스터마이징 기능 남용(학대 등) 예방
- 민감한 정보 및 녹음 파일 암호화 저장
- 이상행동 감지 시 알림 수위 조절 가능
- 데이터 저장 기한 및 사용 명시

---

## 5. 🧩 웹 페이지 구성

### 보호자 페이지

- 회원가입/로그인
- 대시보드: 일일 리포트, 기기 상태, 메모
- 설정: 위험 키워드, 음성 모델, 자녀 정보 관리

---

## 6. 🛠️ 기술 스택

| 구분 | 기술 |
| --- | --- |
| 프론트엔드 | Vue.js |
| 백엔드 | Spring |
| AI 분석 | Whisper.cpp(STT), HuggingFace(LLM 감정 분석), Coqui TTS |
| 데이터 저장 | MySQL, S3(녹음 파일), Redis |
| 디바이스 통신 | MQTT |
| 배포 | AWS (EC2, RDS, S3), nginx |
| IoT | 라즈베리 파이, Jetson Nano |

---

## 7. 📎 참고 아이디어 보류 목록

- 육아일지 기능 (보호자 메모 + 대화 요약 저장)
---

## 8. 🔚 기대 효과

- 아이의 감정을 부모가 보다 쉽게 이해할 수 있음
- 정서적 소통 및 정서 발달에 도움
- 안전 문제 예방 및 이상 징후 빠른 감지
- 자녀 개별 맞춤형 AI 대화로 실생활 밀착 육아 도우미 역할

---

# 프로젝트 회고

## 1. 회고 한 줄 요약

- 혼자 있는 시간이 많은 아이들의 본인의 애착 인형과 자연스럽게 대화할 수 있는 AI 기반 대화형 음성 서비스.
- 한국인 음성 변환이 잘 되는 STT 모델인 OpenAI의 Whisper을 선택하여 웨이크워드 인식률을 높였음. 또한, IoT 기기 안에서 사용할 수 있는 경량화된 모델인 faster-whisper를 통해 온디바이스 AI를 구현하려고 함.
- 정제된 한국인 음성 데이터셋으로 Coqui-TTS의 Xtts 모델을 파인튜닝하여 한국어 음성 변환이 자연스럽도록 함. 또한, 모델을 경량화하여 기기 안에서도 기존의 성능을 잃지 않도록 함.

## 2. 주요 성과 및 하이라이트

- 한국어 음성 변환이 자연스럽지 않은 오픈소스 모델을 파인튜닝하여 음성 변환이 자연스러울 수 있도록 함.
- 5.2GB -> 1.8GB 경량화를 통한 온디바이스 AI를 구현함.
- Frontend에서 Toast, Form 등의 컴포넌트를 만들어 각 페이지에 맞게 코드를 커스텀해서 사용할 수 있도록 함.
- 최종 발표 시, 시연을 통해 실제로 사용하는 듯한 느낌을 청중이 받을 수 있도록 함.

## 3. 도전 과제와 해결 과정

- 문제 1: 선택한 TTS 모델인 Xtts는 한국어 음성 변환을 자연스럽게 하지 못함.
- 해결: Kaggle에서 한국인 여자 음성 데이터셋을 확보하여 모델 학습에 알맞은 데이터셋으로 변환 후, 적절한 파라미터를 설정하여 파인튜닝함.
- 결과: 중국인이 한국어를 발음하는 느낌을 주었던 초기 모델과는 다른 자연스러운 한국어 발음을 구사할 수 있는 모델로 파인튜닝 완료함.

- 문제 2: 파인튜닝한 TTS 모델 사이즈가 커서 IoT 기기 안에서 구동될 수 없었음.
- 해결:
    - 모델 성능을 유지하면서 경량화 진행함.
    - 클라우드 환경을 통해 성능이 좋은 모델을 선택하여 답변 생성이 잘 될 수 있도록 하고 대화의 흐름이 자연스러울 수 있도록 함.
- 결과: 
    - 모델의 성능을 유지하며 사이즈 5.2GB -> 1.8GB 경량화를 성공함.

## 4. Lessons Learned

- 환경적인 요소
    - 온디바이스 AI를 위해 모델을 경량화 하고 양자화 하는 방법을 알게 되었음.
    - 이전의 프로젝트에서 모델 학습 경험과 비교해, 좋은 GPU 환경에서의 모델 학습이 모델의 성능에 중요한 역할을 한다는 것을 알 수 있었음.

- 시도하지 않았던 부분
    - Frontend 파트에서 component를 만들어서 각 페이지에서 불러와서 사용했음. 이를 통해, 만들어 둔 컴포넌트를 재사용하면서 각 페이지에 맞게 커스텀해서 재사용할 수 있었음.

- 협업 관련
    - Jira, Gitlab을 사용하여 스프린트 기간 동안 목표치를 정하고 달성할 수 있었음. 스스로 목표 시간을 설정해 목표를 위해 자신이 할 일을 할 수 있었음. Notion을 통해 미리 정해둔 명세서를 확인하며 프로젝트를 진행할 수 있었음.

## 5. 다음에 시도하고 싶은 것

- 모델 학습 관련
    - 레퍼런스를 참고하여 정확한 방법으로 스스로 모델 학습 로직 구현
    - 온디바이스 AI를 구현한다면, 모델의 특정 부분에 대한 경량화 및 양자화를 통해 반응 속도 개선
    - 모델 튜닝 후, 적절한 평가 방법을 통해 어느 정도로 모델이 개선되었는지를 수치화하는 과정을 거쳐 모델의 성능을 정량적으로 표현

- 각자의 파트에 대한 지식 공유
    - 임베디드 프로젝트를 다시 한다면, 기획 시 HW의 스펙을 꼼꼼히 확인한 후, 사용 가능한 AI 모델을 선정해서 이후의 과정 진행. 실제 구현 실패한 온디바이스 AI를 다시 도전하고 싶음

- 시도해본 파트 관련
    - Frontend 파트를 맡거나 도와줄 일이 있을 경우, 디자인 패턴을 사전에 공유해서 재사용 가능 코드 작성.

- 개인적으로 다음 프로젝트에서 해보고 싶은 것
    - AI 서버 구축을 통한 모델 서빙

## 6. 마무리 한 줄

- 스스로 회고를 작성하며 어떤 부분은 잘했고, 어떤 부분은 부족했는지, 그리고 다음에는 어떤 부분을 더 생각해서 프로젝트를 해야할지 생각해볼 수 있었음.
- 앞으로의 커리어를 위해 어떤 부분에 집중해야하고, 노력해야하는지 깨달음.
- 팀원들과 함께 회고하는 시간을 가지며 각자가 생각했던 부분을 공유할 수 있어서 좋았음.
